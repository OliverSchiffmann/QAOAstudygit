{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c49b24b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#New version of the layer number optimisier script incase i fuck it up\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Packages for quantum stuff\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "from qiskit.circuit.library import QAOAAnsatz\n",
    "from qiskit_aer import AerSimulator\n",
    "from qiskit_ibm_runtime import EstimatorV2 as Estimator, QiskitRuntimeService, SamplerV2 as Sampler\n",
    "from qiskit.transpiler.preset_passmanagers import generate_preset_pass_manager\n",
    "from qiskit_ibm_runtime.fake_provider import FakeBrisbane, FakeSherbrooke, FakeTorino # For simulation with realistic noise\n",
    "\n",
    "objective_func_vals = []\n",
    "numOptimisations = 0 # Tracks iterations within a single minimize call\n",
    "RESULTS_FOLDER = \"depthVsCostResults\"\n",
    "os.makedirs(RESULTS_FOLDER, exist_ok=True) # Ensure results folder exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1127e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_results_filename(problem_type, num_qubits, simulator_name):\n",
    "    # Sanitize simulator_name for filename (e.g., remove specific instance details if any)\n",
    "    sim_name_clean = simulator_name.split('(')[0].replace('-', '_').lower()\n",
    "    return f\"depth_results_{str(problem_type).replace(' ', '_')}_{num_qubits}q_{sim_name_clean}.json\"\n",
    "\n",
    "def load_results_data(filename, current_problem_type, current_num_qubits, current_simulator_name):\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'r') as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                # Validate if the loaded data matches current experiment parameters\n",
    "                if (data.get(\"problem_type\") == current_problem_type and\n",
    "                    data.get(\"num_qubits\") == current_num_qubits and\n",
    "                    data.get(\"simulator_name\") == current_simulator_name):\n",
    "                    print(f\"Successfully loaded existing results from {filename}\")\n",
    "                    return data\n",
    "                else:\n",
    "                    print(f\"Warning: File {filename} exists but metadata does not match current experiment. Starting fresh for this combination.\")\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Warning: File {filename} is corrupted or not valid JSON. Starting fresh.\")\n",
    "    # If file doesn't exist, or loading failed, or metadata mismatch, create a new structure\n",
    "    print(f\"No previous exisiting results found. Creating new data structure for {filename}.\")\n",
    "    return {\n",
    "        \"problem_type\": current_problem_type,\n",
    "        \"num_qubits\": current_num_qubits,\n",
    "        \"simulator_name\": current_simulator_name,\n",
    "        \"results_by_depth\": {} # Stores lists of costs: { \"p_depth_str\": [cost1, cost2, ...] }\n",
    "    }\n",
    "\n",
    "def save_results_data(data, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "    print(f\"Results updated and saved to {filename}\")\n",
    "\n",
    "def load_qubo_and_build_hamiltonian(file_path):\n",
    "    \"\"\"\n",
    "    Loads QUBO terms, weights, and constant from a JSON file.\n",
    "    Determines the number of qubits from the terms and constructs\n",
    "    the Hamiltonian as a Qiskit SparsePauliOp.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\") as f:\n",
    "        all_qubo_data = json.load(f)\n",
    "\n",
    "    if isinstance(all_qubo_data, list):\n",
    "        # If it's a list, take the first element\n",
    "        qubo_data = all_qubo_data[0]\n",
    "    else:\n",
    "        # If it's already a dictionary, just use it directly\n",
    "        qubo_data = all_qubo_data\n",
    "\n",
    "    terms = qubo_data[\"terms\"]\n",
    "    weights = qubo_data[\"weights\"]\n",
    "    constant = qubo_data.get(\"constant\", 0.0)\n",
    "    problemType = qubo_data.get(\"problem_type\")\n",
    "\n",
    "    pauli_list = []\n",
    "    num_qubits = 0\n",
    "\n",
    "    if terms:\n",
    "        # Flatten the list of lists and filter out empty sublists or non-integer elements\n",
    "        all_indices = []\n",
    "        for term_group in terms:\n",
    "            if isinstance(term_group, list): # Ensure it's a list\n",
    "                for idx in term_group:\n",
    "                    if isinstance(idx, int): # Ensure index is an integer\n",
    "                        all_indices.append(idx)\n",
    "\n",
    "        if all_indices: # If there are any valid integer indices\n",
    "            num_qubits = max(all_indices) + 1\n",
    "        else: # No indices and no weights (only constant)\n",
    "            num_qubits = 0\n",
    "    else: # No terms at all\n",
    "        num_qubits = 0\n",
    "        if weights: # Weights present but no terms - problematic\n",
    "            print(\"Warning: Weights are present, but 'terms' list is empty or missing. Cannot form Pauli operators.\")\n",
    "\n",
    "    for term_indices, weight in zip(terms, weights):\n",
    "        if not term_indices or not all(isinstance(idx, int) for idx in term_indices):\n",
    "            # Skip if term_indices is empty or contains non-integers\n",
    "            continue\n",
    "\n",
    "        paulis_arr = [\"I\"] * num_qubits\n",
    "        if len(term_indices) == 1: # Linear term\n",
    "            paulis_arr[term_indices[0]] = \"Z\"\n",
    "        elif len(term_indices) == 2: # Quadratic term\n",
    "            paulis_arr[term_indices[0]] = \"Z\"\n",
    "            paulis_arr[term_indices[1]] = \"Z\"\n",
    "        else:\n",
    "            # This case should ideally not be hit if terms are only single or pairs.\n",
    "            print(f\"Warning: Skipping term {term_indices} with unsupported number of variables for Pauli Z construction.\")\n",
    "            continue\n",
    "        pauli_list.append((\"\".join(paulis_arr)[::-1], weight))\n",
    "\n",
    "    if not pauli_list and num_qubits > 0: # No valid Pauli terms were created, but num_qubits > 0\n",
    "        cost_hamiltonian = SparsePauliOp([\"I\"] * num_qubits, [0]) # Zero operator on n_qubits\n",
    "    elif not pauli_list and num_qubits == 0:\n",
    "        cost_hamiltonian = SparsePauliOp(\"I\", [0]) # Placeholder for 1 qubit if everything is empty\n",
    "    else:\n",
    "        cost_hamiltonian = SparsePauliOp.from_list(pauli_list)\n",
    "\n",
    "    return cost_hamiltonian, constant, num_qubits, problemType\n",
    "\n",
    "def cost_func_estimator(params, ansatz, estimator, cost_hamiltonian_logical, constant_offset): # removed default for backend_total_qubits\n",
    "    global numOptimisations\n",
    "    prepared_observable = cost_hamiltonian_logical.apply_layout(ansatz.layout)\n",
    "    pub = (ansatz, prepared_observable, [params])\n",
    "    \n",
    "    job = estimator.run(pubs=[pub])\n",
    "    results = job.result()[0]\n",
    "    cost = results.data.evs[0]\n",
    "\n",
    "    cost_float = float(np.real(cost)) + constant_offset\n",
    "    objective_func_vals.append(cost_float)\n",
    "    \n",
    "    numOptimisations = numOptimisations + 1\n",
    "    #print(f\"Params: {params}, Cost: {cost_float}, Optimisation Round: {numOptimisations}\") \n",
    "    print(f\"Optimisation Iteration: {numOptimisations}\", end=\"\\r\")  \n",
    "    \n",
    "    return cost_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eec3540f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ///////////    Variables    //////////\n",
    "#cost_hamiltonian, constant_offset, num_qubits, problem_type = load_qubo_and_build_hamiltonian(\"QUBO_batches/batch_QUBO_data_TSP_9q_.json\")\n",
    "qubo_file_paths = [\n",
    "    \"QUBO_batches/batch_QUBO_data_TSP_9q_.json\",\n",
    "    \"QUBO_batches/batch_QUBO_data_Knapsack_9q_.json\"\n",
    "]\n",
    "depth_list = [1, 2, 3] # Depths to test\n",
    "chosenBackend = FakeSherbrooke() #optionsa are FakeBrisbane(), FakeSherbrooke(), FakeTorino(), 'noiseless'\n",
    "\n",
    "# ///////////    New Control Variables    //////////\n",
    "MIN_REPS = 30        # The minimum number of runs for each depth\n",
    "MAX_REPS = 300        # A safety limit to prevent excessively long runs\n",
    "SEM_THRESHOLD = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4edb9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# print(f\"Number of qubits (inferred from terms): {num_qubits}\")\n",
    "# print(\"Problem type:\", problem_type)\n",
    "\n",
    "# if chosenBackend == 'noiseless':\n",
    "#     backend_simulator = AerSimulator()\n",
    "# else:\n",
    "#     backend_simulator = AerSimulator.from_backend(chosenBackend)\n",
    "# estimator = Estimator(mode=backend_simulator)\n",
    "# pm = generate_preset_pass_manager(optimization_level=3, backend=backend_simulator)\n",
    "\n",
    "# if \"fake\" in backend_simulator.name.lower():\n",
    "#     simulator_name_for_file = backend_simulator.name.split('(')[1].lower().replace(')', '')\n",
    "# else:\n",
    "#     simulator_name_for_file = \"aer_simulator_ideal\"\n",
    "\n",
    "# base_filename = generate_results_filename(problem_type, num_qubits, simulator_name_for_file)\n",
    "# results_filename_with_path = os.path.join(RESULTS_FOLDER, base_filename)\n",
    "# ALL_RESULTS_DATA = load_results_data(results_filename_with_path, problem_type, num_qubits, simulator_name_for_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade268e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "===== PROCESSING FILE: QUBO_batches/batch_QUBO_data_TSP_9q_.json =====\n",
      "============================================================\n",
      "Number of qubits: 9\n",
      "Problem type: tsp\n",
      "No previous exisiting results found. Creating new data structure for depthVsCostResults/depth_results_tsp_9q_fake_sherbrooke.json.\n",
      "\n",
      "--- Processing Depth (p): 1 for tsp (9q) on fake_sherbrooke ---\n",
      "  Circuit for depth 1 created. Num params: 2. Transpiled depth: 357\n",
      "  Running Repetition 1 for depth 1...\n",
      "Optimisation Iteration: 5\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/kv18799/Github/QAOAstudygit/IBMQpynbvenv/lib/python3.10/site-packages/scipy/optimize/_cobyla_py.py\", line 281, in calcfc\n",
      "capi_return is NULL\n",
      "Call-back cb_calcfc_in__cobyla__user__routines failed.\n",
      "Fatal Python error: F2PySwapThreadLocalCallbackPtr: F2PySwapThreadLocalCallbackPtr: PyLong_AsVoidPtr failed\n",
      "Python runtime state: initialized\n",
      "    f = sf.fun(x)\n",
      "  File \"/Users/kv18799/Github/QAOAstudygit/IBMQpynbvenv/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 278, in fun\n",
      "    self._update_fun()\n",
      "  File \"/Users/kv18799/Github/QAOAstudygit/IBMQpynbvenv/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 262, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/Users/kv18799/Github/QAOAstudygit/IBMQpynbvenv/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 163, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/Users/kv18799/Github/QAOAstudygit/IBMQpynbvenv/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 145, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/var/folders/ph/hp043kk921q2v4grp3l2v6nw0000gq/T/ipykernel_61802/767809209.py\", line 109, in cost_func_estimator\n",
      "  File \"/Users/kv18799/Github/QAOAstudygit/IBMQpynbvenv/lib/python3.10/site-packages/qiskit/primitives/primitive_job.py\", line 51, in result\n",
      "    return self._future.result()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py\", line 453, in result\n",
      "    self._condition.wait(timeout)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/threading.py\", line 320, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\n",
      "Extension modules: zmq.backend.cython._zmq"
     ]
    }
   ],
   "source": [
    "# ///////////    MODIFIED Iteration and Optimization Loop    //////////\n",
    "for file_path in qubo_file_paths:\n",
    "    print(f\"\\n{'='*60}\\n===== PROCESSING FILE: {file_path} =====\\n{'='*60}\")\n",
    "\n",
    "    cost_hamiltonian, constant_offset, num_qubits, problem_type = load_qubo_and_build_hamiltonian(file_path)\n",
    "\n",
    "    print(f\"Number of qubits: {num_qubits}\")\n",
    "    print(\"Problem type:\", problem_type)\n",
    "\n",
    "    if chosenBackend == 'noiseless':\n",
    "        backend_simulator = AerSimulator()\n",
    "    else:\n",
    "        backend_simulator = AerSimulator.from_backend(chosenBackend)\n",
    "    estimator = Estimator(mode=backend_simulator)\n",
    "    pm = generate_preset_pass_manager(optimization_level=3, backend=backend_simulator)\n",
    "\n",
    "    simulator_name_for_file = backend_simulator.name.split('(')[1].lower().replace(')', '') if \"fake\" in backend_simulator.name.lower() else \"aer_simulator_ideal\"\n",
    "    base_filename = generate_results_filename(problem_type, num_qubits, simulator_name_for_file)\n",
    "    results_filename_with_path = os.path.join(RESULTS_FOLDER, base_filename)\n",
    "    ALL_RESULTS_DATA = load_results_data(results_filename_with_path, problem_type, num_qubits, simulator_name_for_file)\n",
    "\n",
    "    for p_depth in depth_list:\n",
    "        print(f\"\\n--- Processing Depth (p): {p_depth} for {problem_type} ({num_qubits}q) on {simulator_name_for_file} ---\")\n",
    "        \n",
    "        depth_key = str(p_depth) # JSON keys must be strings\n",
    "\n",
    "        # Initialize or retrieve existing results for this depth\n",
    "        if depth_key not in ALL_RESULTS_DATA[\"results_by_depth\"]:\n",
    "            ALL_RESULTS_DATA[\"results_by_depth\"][depth_key] = []\n",
    "        costs_at_this_depth = ALL_RESULTS_DATA[\"results_by_depth\"][depth_key]\n",
    "        \n",
    "        # Prepare the circuit for this depth (done once)\n",
    "        circuit = QAOAAnsatz(cost_operator=cost_hamiltonian, reps=p_depth)\n",
    "        candidate_circuit = pm.run(circuit)\n",
    "        print(f\"  Circuit for depth {p_depth} created. Num params: {2*p_depth}. Transpiled depth: {candidate_circuit.depth()}\")\n",
    "        \n",
    "        previous_sem = float('inf')  # Initialize with a large value\n",
    "\n",
    "        # Loop until convergence criteria are met or max repetitions are reached\n",
    "        while len(costs_at_this_depth) < MAX_REPS:\n",
    "            num_runs_so_far = len(costs_at_this_depth)\n",
    "\n",
    "            # Check for convergence if we have completed the minimum number of repetitions\n",
    "            if num_runs_so_far >= MIN_REPS and num_runs_so_far % 5 == 0:\n",
    "                # Calculate Standard Error of the Mean (SEM) using sample standard deviation (ddof=1)\n",
    "                current_sem = np.std(costs_at_this_depth, ddof=1) / np.sqrt(num_runs_so_far)\n",
    "                sem_change = abs(previous_sem - current_sem)\n",
    "                \n",
    "                print(f\"  Run {num_runs_so_far}: Current SEM = {current_sem:.6f}, Change from previous = {sem_change:.6f}\")\n",
    "\n",
    "                if sem_change < SEM_THRESHOLD:\n",
    "                    print(f\"  Convergence met: SEM change ({sem_change:.6f}) is below threshold ({SEM_THRESHOLD}).\")\n",
    "                    break # Exit the while loop for this depth\n",
    "                previous_sem = current_sem\n",
    "\n",
    "            # --- Perform one optimization run ---\n",
    "            print(f\"  Running Repetition {num_runs_so_far + 1} for depth {p_depth}...\")\n",
    "            \n",
    "            objective_func_vals = [] # Reset for each minimize call\n",
    "            numOptimisations = 0   # Reset for each minimize call\n",
    "\n",
    "            num_params = 2 * p_depth\n",
    "            initial_params = np.random.rand(num_params) * np.pi\n",
    "            \n",
    "            result = minimize(\n",
    "                cost_func_estimator,\n",
    "                initial_params,\n",
    "                args=(candidate_circuit, estimator, cost_hamiltonian, constant_offset),\n",
    "                method=\"COBYLA\",\n",
    "                tol=1e-3,\n",
    "                options={\"maxiter\": 1000} \n",
    "            )\n",
    "            final_cost = float(f\"{result.fun:.4f}\")\n",
    "            print(f\"\\n  Completed Rep {num_runs_so_far + 1}: Optimal Cost = {final_cost}\") # Added newline for clarity\n",
    "\n",
    "            # Add the new result and save progress immediately\n",
    "            costs_at_this_depth.append(final_cost)\n",
    "            ALL_RESULTS_DATA[\"results_by_depth\"][depth_key] = costs_at_this_depth\n",
    "            save_results_data(ALL_RESULTS_DATA, results_filename_with_path)\n",
    "\n",
    "        else: # This 'else' clause executes if the while loop finishes without a 'break'\n",
    "            print(f\"  Reached maximum repetitions ({MAX_REPS}) for depth {p_depth}. Stopping.\")\n",
    "    print(f\"\\n--- All depths processed for {file_path} ---\")\n",
    "\n",
    "print(\"\\n--- All depths processed ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IBMQpynbvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
